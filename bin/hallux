#!/bin/env python
# Copyright: Hallux team, 2023

# MAIN COMMAND-LINE EXECUTABLE
# - Runs checks in the current folder (linting / unit-tests / docstrings / compilation errors)
# - Extracts every single message
# - Makes a prompt for every message
# - Sends prompt to GPT, receives answer,
# - Changes code right in the codebase or sends this change as Github Web GUI proposal


from __future__ import annotations

import copy
import subprocess
import os
import sys
import tempfile

from typing import Final
import yaml
import re
from pathlib import Path
import openai
from numpy.core.defchararray import isnumeric

from query_backend import QueryBackend, OpenAiChatGPT
from diff_target import DiffTarget, FilesystemTarget, GitCommitTarget, GithubProposalTraget
from cpp import CppExecutor



def load_config() -> tuple[dict | None, Path | None]:
    curr_path = Path(os.getcwd())
    while not curr_path.joinpath(".hallux").exists() and curr_path.parent != curr_path:
        curr_path = curr_path.parent
    if not curr_path.joinpath(".hallux").exists():
        return None, None
    config_file = str(curr_path.joinpath(".hallux"))
    with open(config_file) as file_stream:
        yaml_dict = yaml.load(file_stream, Loader=yaml.CLoader)
    return yaml_dict, curr_path


class Hallux:
    def __init__(self, query_backend: QueryBackend, config: dict, base_path: Path, diff_target: DiffTarget):
        self.query_backend = query_backend
        self.config: Final[dict] = config
        self.base_path: Final[Path] = base_path
        self.diff_target: Final[DiffTarget] = diff_target
        self.debug: bool = True

    def process(self):
        if "python" in self.config.keys():
            self.python(self.config["python"])
        if "cpp" in self.config.keys():
            cpp = CppExecutor(self.query_backend, self.diff_target, self.base_path, self.config["cpp"], self.debug)
            cpp.process()

    def python(self, config: dict):
        print("Process Python issues:")
        if "linting" in config.keys():
            self.python_linting(config["linting"])
        if "tests" in config.keys():
            self.python_tests(config["tests"])
        if "docstrings" in config:
            self.python_docstrings(config["docstrings"])

    def python_linting(self, params: str | None):
        if params is None or params == "ruff":
            self.python_linting_ruff(["ruff", "check", "."])
        else:
            print("We only support RUFF for python lint")
            exit(5)

    @staticmethod
    def read_lines(filename: str, line: int, raidus: int, add_comment:str|None = None) -> tuple[int, int, list[str], list[str]]:
        with open(filename, "rt") as file:
            filelines = file.read().split("\n")
        start_line = max(0, line - raidus)
        end_line = min(len(filelines) - 1, line + raidus)
        requested_lines = copy.deepcopy(filelines[start_line:end_line])
        requested_lines[line-start_line+1] += add_comment
        return start_line, end_line, requested_lines, filelines

    @staticmethod
    def prepare_lines(query_result: str, remove_comment:str|None = None) -> list[str]:
        resulting_lines = query_result.split("\n")
        for i in range(len(resulting_lines)):
            line : str = resulting_lines[i]
            if line.endswith(remove_comment):
                resulting_lines[i] = line[:-len(remove_comment)]
                break
        return resulting_lines

    def python_linting_ruff(self, command):
        print("Process python linting issues:")

        try:
            subprocess.check_output(command)
            print("No python linting issues found")
        except subprocess.CalledProcessError as e:
            ruff_output = e.output

            warnings: list[str] = str(ruff_output.decode("utf-8")).split("\n")
            for warn in warnings[:-2]:
                print(warn)
                filename = warn.split(" ")[0].split(":")[0]
                warn_line = int(warn.split(" ")[0].split(":")[1])
                added_comment: str = " # line " + str(warn_line)
                start_line, end_line, warnlines, filelines = self.read_lines(filename, warn_line, 4, added_comment)

                # with open(filename, "rt") as file:
                #     filelines = file.read().split("\n")

                request = "Fix python linting issue, write resulting code only:\n"
                request = request + warn + "\n"
                request = request + "Excerpt from the corresponding python file (not full):\n"

                for line in warnlines:
                    request = request + line + "\n"

                print("request")
                print(request)

                result : str

                if self.debug:
                    result = ["        try:\n" + \
                                     "            token1 = next(tokens1)\n" + \
                                     "            token2 = next(tokens2)\n" + \
                                     "        except:\n" + \
                                     "            break\n\n@pytest.mark.parametrize(\n"]

                else:
                    result = self.query_backend.query(request)

                    # result = ChatCompletion.create(messages=[{"role": "user", "content": request}], model=self.model)
                    # print("result")
                    # print(result)
                    #
                    # if len(result["choices"]) > 0:
                    #     print(result["choices"])
                    #     for variant in result["choices"]:
                    #         resulting_code = variant["message"]["content"]


                if len(result) > 0:
                    #resulting_code : str = result[0]
                    # resulting_lines = resulting_code.split("\n")
                    # for i in range(len(resulting_lines)):
                    #     line : str = resulting_lines[i]
                    #     if line.endswith(added_comment):
                    #         resulting_lines[i] = line[:-len(added_comment)]
                    #         break
                    resulting_lines = self.prepare_lines(result[0], added_comment)

                    self.diff_target.apply_diff(filename, start_line, end_line, resulting_lines, warn)

                if self.debug:
                    break

    def python_tests(self, params: dict | str):
        pass

    def python_docstrings(self, params: dict | str):
        pass





if __name__ == "__main__":
    print("Hallux v0.1 - Convenient Coding Assistant")
    if len(sys.argv) < 2 or sys.argv[1] not in ["fix", "propose", "commit"]:
        print("Usage: hallux fix | hallux commit  | hallux propose Github_PullRequest_ID")
        exit(0)

    config, path = load_config()
    if config is None:
        print("Error: config file not found")
        exit(1)

    if not "backend" in config or "openai" not in config["backend"]:
        print("Backend is not properly configured")
        exit(2)

    query_backend: QueryBackend = OpenAiChatGPT(config["backend"]["openai"])

    target: DiffTarget

    if sys.argv[1] == "fix":
        target = FilesystemTarget()
    elif sys.argv[1] == "commit":
        target = GitCommitTarget()
    else:
        target = GithubProposalTraget(sys.argv[2])

    openai.api_key = os.getenv("OPENAI_API_KEY")

    hallux = Hallux(query_backend=query_backend, config=config, base_path=path, diff_target=target)

    hallux.process()

